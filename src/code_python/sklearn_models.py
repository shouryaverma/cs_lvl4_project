# -*- coding: utf-8 -*-
"""sklearn_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HH7akK7j_0dbBeY2m84NkwTX1wuCEump
"""

!pip install eli5

import numpy as np
import glob
import matplotlib.pyplot as plt
import pandas as pd
from scipy import *


##use this for holdout 25/75 >>>>>>>>>>>>>>>.
# train_values = np.empty(shape=[0, 222])
# test_values = np.empty(shape=[0, 222])

# train_sampled_all = glob.glob('./drive/MyDrive/compsci/train_sampled_all_220.csv')
# test_unsampled_all = glob.glob('./drive/MyDrive/compsci/test_unsampled_all_220.csv')

# for j in train_sampled_all:
#     print('Loading ', j)
#     csvrows = np.loadtxt(j, delimiter=',')
#     train_values = np.append(train_values, csvrows, axis=0)

# for j in test_unsampled_all:
#     print('Loading ', j)
#     csvrows = np.loadtxt(j, delimiter=',')
#     test_values = np.append(test_values, csvrows, axis=0)
    
# print(train_values.shape)
# print(test_values.shape)

## use this for leave patients >>>>>>>>>>>>>>>.

train_values = np.empty(shape=[0, 222])
test_values = np.empty(shape=[0, 222])

train_patients = glob.glob('./drive/MyDrive/compsci/train_patients.csv')
test_patients = glob.glob('./drive/MyDrive/compsci/test_patients.csv')

for j in train_patients:
    print('Loading ', j)
    csvrows = np.loadtxt(j, delimiter=',')
    train_values = np.append(train_values, csvrows, axis=0)

for j in test_patients:
    print('Loading ', j)
    csvrows = np.loadtxt(j, delimiter=',')
    test_values = np.append(test_values, csvrows, axis=0)
    
print(train_values.shape)
print(test_values.shape)

X_train = train_values[:,:-2]
X_test = test_values[:,:-2]

y_train = train_values[:,-2]
y_test = test_values[:,-2]

from itertools import islice

def means_of_slices(iterable, slice_size):
    iterator = iter(iterable)
    while True:
        slice = list(islice(iterator, slice_size))
        if slice:
            yield np.sum(slice)/len(slice)
        else:
            return

a = X_train
new_X_train = []
for i in range(len(X_train)):
  means = list(means_of_slices(a[i], 20))
  new_X_train.append(means)
X_train = np.array(new_X_train)
# X_train = []
# for i in new_X_train:
#   X_train.append(np.repeat(i,17))
# X_train = np.array(X_train)
# print(X_train.shape)

b = X_test
new_X_test = []
for i in range(len(X_test)):
  means = list(means_of_slices(b[i], 20))
  new_X_test.append(means)
X_test = np.array(new_X_test)
# X_test = []
# for i in new_X_test:
#   X_test.append(np.repeat(i,17))
# X_test = np.array(X_test)
# print(X_test.shape)

from sklearn.metrics import *
def showResults(test, pred, model_name):
    #target_names = ['positive', 'negative']
    # print(classification_report(test, pred, target_names=target_names))
    accuracy = accuracy_score(test, pred)
    precision= precision_score(test, pred, average='macro')
    recall = recall_score(test, pred, average = 'macro')
    f1score= f1_score(test, pred, average='macro') 
    #loss=log_loss(test,pred)
    print("Accuracy  : {}".format(accuracy))
    print("Precision : {}".format(precision))
    print("Recall : {}".format(recall))
    print("f1score : {}".format(f1score))
    #print("Loss : {}".format(loss))
    cm=confusion_matrix(test, pred,labels=[1,2,3,4,5,6,7,8])
    cm = np.nan_to_num(cm)
    print(cm)
    return (model_name, round(accuracy,3), round(precision,3) , round(recall,3) , round(f1score,3), cm)

# using gradient boost classifier
from sklearn.ensemble import GradientBoostingClassifier
gbc_clf = GradientBoostingClassifier(n_estimators=100,random_state=48, n_iter_no_change=5,tol=0.1)
gbc_clf.fit(X_train, y_train)
print('Gradient Boosting Results')
y_pred_gbc = gbc_clf.predict(X_test)
print(gbc_clf.score(X_test,y_test))

# using adaboost classifier
from sklearn.ensemble import AdaBoostClassifier
ada_clf = AdaBoostClassifier(n_estimators=100,random_state=48)
ada_clf.fit(X_train, y_train)
print('Ada Boosting Results')
y_pred_ada = ada_clf.predict(X_test)
print(ada_clf.score(X_test,y_test))

# using random forest classifier
from sklearn.ensemble import RandomForestClassifier
rfc_clf = RandomForestClassifier(max_depth=10, random_state=48,n_estimators=10)
rfc_clf.fit(X_train, y_train)
print('Random Forest Results')
y_pred_rfc = rfc_clf.predict(X_test)
print(rfc_clf.score(X_test, y_test))

# using naive bayes
from sklearn.naive_bayes import GaussianNB
NB_clf = GaussianNB()
NB_clf.fit(X_train, y_train)
print('Naive Bayes Results')
y_pred_NB = NB_clf.predict(X_test)
print(NB_clf.score(X_test, y_test))

# using NN Multi Layer Perceptron classifier
from sklearn.neural_network import MLPClassifier
NNMLP_clf = MLPClassifier(random_state=48, max_iter=100)
NNMLP_clf.fit(X_train, y_train)
print('NNMLP Results')
y_pred_NNMLP = NNMLP_clf.predict(X_test)
print(NNMLP_clf.score(X_test, y_test))

#support vector classifier
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
svc_clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))
svc_clf.fit(X_train, y_train)
print('Support Vector Results')
y_pred_svc = svc_clf.predict(X_test)
print(svc_clf.score(X_test,y_test))

##Use only when running on all data
gbc_results = showResults(y_test, y_pred_gbc,'GBC')
ada_results = showResults(y_test, y_pred_ada,'ADA')
rfc_results = showResults(y_test, y_pred_rfc,'RFC')
nb_results = showResults(y_test, y_pred_NB,'NB')
nnmlp_results = showResults(y_test, y_pred_NNMLP,'NNMLP')
svc_results = showResults(y_test, y_pred_svc,'SVC')

misclass_gbc = np.where(y_pred_gbc!=y_test)
misclass_gbc = misclass_gbc[0].tolist()
print(misclass_gbc)

correct_gbc = np.where(y_pred_gbc==y_test)
correct_gbc = correct_gbc[0].tolist()
print(correct_gbc)

import eli5
from eli5.sklearn import PermutationImportance
from IPython.display import display

perm_gbc = PermutationImportance(gbc_clf).fit(X_test, y_test)
print('GBC Results')
exp_gbc = eli5.explain_weights_df(perm_gbc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_gbc = PermutationImportance(gbc_clf).fit(X_test[correct_gbc[:]], y_test[correct_gbc[:]])
print('GBC Correct Results')
exp_gbc_corr = eli5.explain_weights_df(perm_gbc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_gbc = PermutationImportance(gbc_clf).fit(X_test[misclass_gbc[:]], y_test[misclass_gbc[:]])
print('GBC Misclass Results')
exp_gbc_mis = eli5.explain_weights_df(perm_gbc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

misclass_ada = np.where(y_pred_ada!=y_test)
misclass_ada = misclass_ada[0].tolist()
print(misclass_ada)

correct_ada = np.where(y_pred_ada==y_test)
correct_ada = correct_ada[0].tolist()
print(correct_ada)

perm_ada = PermutationImportance(ada_clf).fit(X_test, y_test)
print('ADA Results')
exp_ada = eli5.explain_weights_df(perm_ada, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_ada = PermutationImportance(ada_clf).fit(X_test[correct_ada[:]], y_test[correct_ada[:]])
print('ADA Correct Results')
exp_ada_corr = eli5.explain_weights_df(perm_ada, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_ada = PermutationImportance(ada_clf).fit(X_test[misclass_ada[:]], y_test[misclass_ada[:]])
print('ADA Misclass Results')
exp_ada_mis = eli5.explain_weights_df(perm_ada, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

misclass_rfc = np.where(y_pred_rfc!=y_test)
misclass_rfc = misclass_rfc[0].tolist()
print(misclass_rfc)

correct_rfc = np.where(y_pred_rfc==y_test)
correct_rfc = correct_rfc[0].tolist()
print(correct_rfc)

perm_rfc = PermutationImportance(rfc_clf).fit(X_test, y_test)
print('RFC Results')
exp_rfc = eli5.explain_weights_df(perm_rfc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_rfc =PermutationImportance(rfc_clf).fit(X_test[correct_rfc[:]], y_test[correct_rfc[:]])
print('RFC Correct Results')
exp_rfc_corr = eli5.explain_weights_df(perm_rfc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_rfc =PermutationImportance(rfc_clf).fit(X_test[misclass_rfc[:]], y_test[misclass_rfc[:]])
print('RFC Misclass Results')
exp_rfc_mis = eli5.explain_weights_df(perm_rfc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

misclass_nb = np.where(y_pred_NB!=y_test)
misclass_nb = misclass_nb[0].tolist()
print(misclass_nb)

correct_nb = np.where(y_pred_NB==y_test)
correct_nb = correct_nb[0].tolist()
print(correct_nb)

perm_nb = PermutationImportance(NB_clf).fit(X_test, y_test)
print('NB Results')
exp_nb = eli5.explain_weights_df(perm_nb, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_nb =PermutationImportance(NB_clf).fit(X_test[correct_nb[:]], y_test[correct_nb[:]])
print('NB Correct Results')
exp_nb_corr = eli5.explain_weights_df(perm_nb, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_nb =PermutationImportance(NB_clf).fit(X_test[misclass_nb[:]], y_test[misclass_nb[:]])
print('NB Misclass Results')
exp_nb_mis = eli5.explain_weights_df(perm_nb, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

misclass_nnmlp = np.where(y_pred_NNMLP!=y_test)
misclass_nnmlp = misclass_nnmlp[0].tolist()
print(misclass_nnmlp)

correct_nnmlp = np.where(y_pred_NNMLP==y_test)
correct_nnmlp = correct_nnmlp[0].tolist()
print(correct_nnmlp)

perm_nnmlp = PermutationImportance(NNMLP_clf).fit(X_test, y_test)
print('NNMLP Results')
exp_nnmlp = eli5.explain_weights_df(perm_nnmlp, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_nnmlp =PermutationImportance(NNMLP_clf).fit(X_test[correct_nnmlp[:]], y_test[correct_nnmlp[:]])
print('NNMLP Correct Results')
exp_nnmlp_corr = eli5.explain_weights_df(perm_nnmlp, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_nnmlp =PermutationImportance(NNMLP_clf).fit(X_test[misclass_nnmlp[:]], y_test[misclass_nnmlp[:]])
print('NNMLP Misclass Results')
exp_nnmlp_mis = eli5.explain_weights_df(perm_nnmlp, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

misclass_svc = np.where(y_pred_svc!=y_test)
misclass_svc = misclass_svc[0].tolist()
print(misclass_svc)

correct_svc = np.where(y_pred_svc==y_test)
correct_svc = correct_svc[0].tolist()
print(correct_svc)

perm_svc = PermutationImportance(svc_clf).fit(X_test, y_test)
print('SVC Results')
exp_svc = eli5.explain_weights_df(perm_svc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_svc =PermutationImportance(svc_clf).fit(X_test[correct_svc[:]], y_test[correct_svc[:]])
print('SVC Correct Results')
exp_svc_corr = eli5.explain_weights_df(perm_svc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

perm_svc =PermutationImportance(svc_clf).fit(X_test[misclass_svc[:]], y_test[misclass_svc[:]])
print('SVC Misclass Results')
exp_svc_mis = eli5.explain_weights_df(perm_svc, feature_names = [0,1,2,3,4,5,6,7,8,9,10])

from sklearn import metrics

metrics_gbc = metrics.classification_report(y_test, y_pred_gbc, digits=3)
metrics_ada = metrics.classification_report(y_test, y_pred_ada, digits=3)
metrics_rfc = metrics.classification_report(y_test, y_pred_rfc, digits=3)
metrics_NB = metrics.classification_report(y_test, y_pred_NB, digits=3)
metrics_NNMLP = metrics.classification_report(y_test, y_pred_NNMLP, digits=3)
metrics_svc = metrics.classification_report(y_test, y_pred_svc, digits=3)

print(metrics_gbc, 'gbc metrics')
print(metrics_ada, 'ada metrics')
print(metrics_rfc, 'rfc metrics')
print(metrics_NB, 'NB metrics')
print(metrics_NNMLP, 'NNMLP metrics')
print(metrics_svc, 'svc metrics')

import seaborn as sns
from sklearn.metrics import *
import matplotlib.pyplot as plt

categories = ['N','L','R','V','A','F','f','/']

gbc_cf_m = confusion_matrix(y_test,y_pred_gbc,labels=[1,2,3,4,5,6,7,8])
gbc_cf_m = gbc_cf_m.astype('float')/ gbc_cf_m.sum(axis=1)[:,np.newaxis]
gbc_pr_s = precision_score(y_test,y_pred_gbc,average='weighted')

ada_cf_m = confusion_matrix(y_test,y_pred_ada,labels=[1,2,3,4,5,6,7,8])
ada_cf_m = ada_cf_m.astype('float')/ ada_cf_m.sum(axis=1)[:,np.newaxis]
ada_pr_s = precision_score(y_test,y_pred_ada,average='weighted')

rfc_cf_m = confusion_matrix(y_test,y_pred_rfc,labels=[1,2,3,4,5,6,7,8])
rfc_cf_m = rfc_cf_m.astype('float')/ rfc_cf_m.sum(axis=1)[:,np.newaxis]
rfc_pr_s = precision_score(y_test,y_pred_rfc,average='weighted')

NB_cf_m = confusion_matrix(y_test,y_pred_NB,labels=[1,2,3,4,5,6,7,8])
NB_cf_m = NB_cf_m.astype('float')/ NB_cf_m.sum(axis=1)[:,np.newaxis]
NB_pr_s = precision_score(y_test,y_pred_NB,average='weighted')

NNMLP_cf_m = confusion_matrix(y_test,y_pred_NNMLP,labels=[1,2,3,4,5,6,7,8])
NNMLP_cf_m = NNMLP_cf_m.astype('float')/ NNMLP_cf_m.sum(axis=1)[:,np.newaxis]
NNMLP_pr_s = precision_score(y_test,y_pred_NNMLP,average='weighted')

svc_cf_m = confusion_matrix(y_test,y_pred_svc,labels=[1,2,3,4,5,6,7,8])
svc_cf_m = svc_cf_m.astype('float')/ svc_cf_m.sum(axis=1)[:,np.newaxis]
svc_pr_s = precision_score(y_test,y_pred_svc,average='weighted')

plt.figure(figsize=(8,6))
sns.heatmap(np.nan_to_num(gbc_cf_m),annot=True,fmt='.2%',xticklabels=categories,yticklabels=categories)
plt.title('GBC confusion matrix')
# plt.savefig('gbc_cfm.jpeg')

plt.figure(figsize=(8,6))
sns.heatmap(np.nan_to_num(ada_cf_m),annot=True,fmt='.2%',xticklabels=categories,yticklabels=categories)
plt.title('ADA confusion matrix')
# plt.savefig('ada_cfm.jpeg')

plt.figure(figsize=(8,6))
sns.heatmap(np.nan_to_num(rfc_cf_m),annot=True,fmt='.2%',xticklabels=categories,yticklabels=categories)
plt.title('RFC confusion matrix')
# plt.savefig('rfc_cfm.jpeg')

plt.figure(figsize=(8,6))
sns.heatmap(np.nan_to_num(NB_cf_m),annot=True,fmt='.2%',xticklabels=categories,yticklabels=categories)
plt.title('NB confusion matrix')
# plt.savefig('NB_cfm.jpeg')

plt.figure(figsize=(8,6))
sns.heatmap(np.nan_to_num(NNMLP_cf_m),annot=True,fmt='.2%',xticklabels=categories,yticklabels=categories)
plt.title('NNMLP confusion matrix')
# plt.savefig('NNMLP_cfm.jpeg')

plt.figure(figsize=(8,6))
sns.heatmap(np.nan_to_num(svc_cf_m),annot=True,fmt='.2%',xticklabels=categories,yticklabels=categories)
plt.title('SVC confusion matrix')
# plt.savefig('SVC_cfm.jpeg')

# exp_gbc = exp_gbc.sort_values(by=['feature'])
# exp_gbc_corr = exp_gbc_corr.sort_values(by=['feature'])
# exp_gbc_mis = exp_gbc_mis.sort_values(by=['feature'])

# exp_gbc.to_csv('./drive/MyDrive/compsci/leave_pfi/gbc_pfi.csv', encoding='utf-8', index=False)
# exp_gbc_corr.to_csv('./drive/MyDrive/compsci/leave_pfi/gbc_pfi_corr.csv', encoding='utf-8', index=False)
# exp_gbc_mis.to_csv('./drive/MyDrive/compsci/leave_pfi/gbc_pfi_mis.csv', encoding='utf-8', index=False)

# exp_ada = exp_ada.sort_values(by=['feature'])
# exp_ada_corr = exp_ada_corr.sort_values(by=['feature'])
# exp_ada_mis = exp_ada_mis.sort_values(by=['feature'])

# exp_ada.to_csv('./drive/MyDrive/compsci/leave_pfi/ada_pfi.csv', encoding='utf-8', index=False)
# exp_ada_corr.to_csv('./drive/MyDrive/compsci/leave_pfi/ada_pfi_corr.csv', encoding='utf-8', index=False)
# exp_ada_mis.to_csv('./drive/MyDrive/compsci/leave_pfi/ada_pfi_mis.csv', encoding='utf-8', index=False)

# exp_rfc = exp_rfc.sort_values(by=['feature'])
# exp_rfc_corr = exp_rfc_corr.sort_values(by=['feature'])
# exp_rfc_mis = exp_rfc_mis.sort_values(by=['feature'])

# exp_rfc.to_csv('./drive/MyDrive/compsci/leave_pfi/rfc_pfi.csv', encoding='utf-8', index=False)
# exp_rfc_corr.to_csv('./drive/MyDrive/compsci/leave_pfi/rfc_pfi_corr.csv', encoding='utf-8', index=False)
# exp_rfc_mis.to_csv('./drive/MyDrive/compsci/leave_pfi/rfc_pfi_mis.csv', encoding='utf-8', index=False)

# exp_nb = exp_nb.sort_values(by=['feature'])
# exp_nb_corr = exp_nb_corr.sort_values(by=['feature'])
# exp_nb_mis = exp_nb_mis.sort_values(by=['feature'])

# exp_nb.to_csv('./drive/MyDrive/compsci/leave_pfi/nb_pfi.csv', encoding='utf-8', index=False)
# exp_nb_corr.to_csv('./drive/MyDrive/compsci/leave_pfi/nb_pfi_corr.csv', encoding='utf-8', index=False)
# exp_nb_mis.to_csv('./drive/MyDrive/compsci/leave_pfi/nb_pfi_mis.csv', encoding='utf-8', index=False)

# exp_nnmlp = exp_nnmlp.sort_values(by=['feature'])
# exp_nnmlp_corr = exp_nnmlp_corr.sort_values(by=['feature'])
# exp_nnmlp_mis = exp_nnmlp_mis.sort_values(by=['feature'])

# exp_nnmlp.to_csv('./drive/MyDrive/compsci/leave_pfi/nnmlp_pfi.csv', encoding='utf-8', index=False)
# exp_nnmlp_corr.to_csv('./drive/MyDrive/compsci/leave_pfi/nnmlp_pfi_corr.csv', encoding='utf-8', index=False)
# exp_nnmlp_mis.to_csv('./drive/MyDrive/compsci/leave_pfi/nnmlp_pfi_mis.csv', encoding='utf-8', index=False)

# exp_svc = exp_svc.sort_values(by=['feature'])
# exp_svc_corr = exp_svc_corr.sort_values(by=['feature'])
# exp_svc_mis = exp_svc_mis.sort_values(by=['feature'])

# exp_svc.to_csv('./drive/MyDrive/compsci/leave_pfi/svc_pfi.csv', encoding='utf-8', index=False)
# exp_svc_corr.to_csv('./drive/MyDrive/compsci/leave_pfi/svc_pfi_corr.csv', encoding='utf-8', index=False)
# exp_svc_mis.to_csv('./drive/MyDrive/compsci/leave_pfi/svc_pfi_mis.csv', encoding='utf-8', index=False)

# def showResults(test, pred, model_name):
#     #target_names = ['positive', 'negative']
#     # print(classification_report(test, pred, target_names=target_names))
#     accuracy = accuracy_score(test, pred)
#     precision= precision_score(test, pred, average='weighted')
#     recall = recall_score(test, pred, average = 'weighted')
#     f1score= f1_score(test, pred, average='weighted') 
#     #loss=log_loss(test,pred)
#     print("Accuracy  : {}".format(accuracy))
#     print("Precision : {}".format(precision))
#     print("Recall : {}".format(recall))
#     print("f1score : {}".format(f1score))
#     #print("Loss : {}".format(loss))
#     cm=confusion_matrix(test, pred)
#     print(cm)
#     return (model_name, round(accuracy,3), round(precision,3) , round(recall,3) , round(f1score,3), cm)

sklearn_results = pd.DataFrame(data=(gbc_results,ada_results,rfc_results,
                                     nb_results,nnmlp_results,svc_results),
                               index=('Model','Accuracy','Precision','Recall','F1score','CM'))
print(sklearn_results)
sklearn_results.to_csv('sklearn_results.csv', encoding='utf-8', index=False)

print(sklearn_results.to_string())