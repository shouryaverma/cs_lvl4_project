{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "leave_patients.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ_o6QIohcVH"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold, LeaveOneGroupOut, LeavePGroupsOut, LeavePOut\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import *\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from statistics import mean, stdev\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "from scipy.stats.stats import kendalltau\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import log_loss\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D, Conv1DTranspose\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import LSTM, Masking\n",
        "from tensorflow.keras.layers import MaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras import activations\n",
        "from sklearn.utils import resample\n",
        "sns.set()\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import *\n",
        "import seaborn as sns\n",
        "from statistics import mean, stdev\n",
        "sns.set()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fhCcAqVBFpf",
        "outputId": "7d4571fd-49d7-4be0-ea92-f4fe257a807b"
      },
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy import *\n",
        "\n",
        "data = np.empty(shape=[0, 222])\n",
        "\n",
        "all_data = glob.glob('./drive/MyDrive/compsci/all_data.csv')\n",
        "\n",
        "for j in all_data:\n",
        "    print('Loading ', j)\n",
        "    csvrows = np.loadtxt(j, delimiter=',')\n",
        "    data = np.append(data, csvrows, axis=0)\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "train_patients = np.empty(shape=[0, 222])\n",
        "test_patients = np.empty(shape=[0, 222])\n",
        "patient_number = [104,208,113,210,119]\n",
        "\n",
        "indices = []\n",
        "noindices = []\n",
        "\n",
        "for j in range(len(patient_number)):\n",
        "  index = [i for i, x in enumerate(data[:,-1]) if x == patient_number[j]]\n",
        "  noindex = [i for i, x in enumerate(data[:,-1]) if x != patient_number[j]]\n",
        "  indices = np.append(indices, index, axis=0 )\n",
        "  noindices = np.append(noindices, noindex, axis = 0)\n",
        "\n",
        "test_patients = data[indices.astype(int).tolist()]\n",
        "print(test_patients.shape)\n",
        "train_patients = data[noindices.astype(int).tolist()]\n",
        "print(train_patients.shape)\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "N = train_patients[train_patients[:,-2]==1.0]\n",
        "L = train_patients[train_patients[:,-2]==2.0]\n",
        "R = train_patients[train_patients[:,-2]==3.0]\n",
        "V = train_patients[train_patients[:,-2]==4.0]\n",
        "A = train_patients[train_patients[:,-2]==5.0]\n",
        "F = train_patients[train_patients[:,-2]==6.0]\n",
        "f = train_patients[train_patients[:,-2]==7.0]\n",
        "I = train_patients[train_patients[:,-2]==8.0]\n",
        "\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "def downsample(arr, n, seed):\n",
        "    downsampled = resample(arr,replace=False,n_samples=n, random_state=seed)\n",
        "    return downsampled\n",
        "\n",
        "def upsample(arr, n, seed):\n",
        "    upsampled = resample(arr,replace=True,n_samples=n,random_state=seed)\n",
        "    return upsampled\n",
        "\n",
        "all_class = [N,L,R,V,A,F,f,I]\n",
        "abn_class = [L,R,V,A,F,f,I]\n",
        "\n",
        "mean_val = np.mean([len(i) for i in abn_class], dtype= int)\n",
        "train_sampled = []\n",
        "\n",
        "for i in all_class:\n",
        "    if i.shape[0]> mean_val:\n",
        "        i = downsample(i,mean_val,seed)\n",
        "    elif i.shape[0]< mean_val:\n",
        "        i = upsample(i, mean_val,seed)\n",
        "    train_sampled.append(i)\n",
        "    \n",
        "train_sampled = np.concatenate(train_sampled)\n",
        "np.random.shuffle(train_sampled)\n",
        "train_sampled_all = train_sampled\n",
        "\n",
        "with open('train_patients.csv', \"wb\") as fin:\n",
        "    np.savetxt(fin, train_sampled_all, delimiter=\",\", fmt='%f')\n",
        "\n",
        "with open('test_patients.csv', \"wb\") as fin:\n",
        "    np.savetxt(fin, test_patients, delimiter=\",\", fmt='%f')\n",
        "\n",
        "print(train_sampled_all.shape)\n",
        "print(test_patients.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading  ./drive/MyDrive/compsci/all_data.csv\n",
            "(151452, 222)\n",
            "(14380, 222)\n",
            "(742880, 222)\n",
            "(206312, 222)\n",
            "(14380, 222)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}