{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cross_val_keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExTXqOFftnrL"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from pylab import rcParams\r\n",
        "from scipy.stats.stats import kendalltau\r\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\r\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from sklearn.utils import class_weight\r\n",
        "from sklearn.metrics import log_loss\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import Input\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\r\n",
        "from tensorflow.keras.models import Model, load_model\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Conv1D, Conv1DTranspose\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras.layers import LSTM, Masking\r\n",
        "from tensorflow.keras.layers import MaxPooling1D, GlobalAveragePooling1D\r\n",
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "from tensorflow.keras import activations\r\n",
        "sns.set()\r\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxRganT3t1ZJ",
        "outputId": "68ad745b-a56d-48a2-ac79-ee0176b3ead6"
      },
      "source": [
        "import numpy as np\r\n",
        "import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from scipy import *\r\n",
        "\r\n",
        "data = np.empty(shape=[0, 222])\r\n",
        "\r\n",
        "all_data = glob.glob('./drive/MyDrive/compsci/all_data.csv')\r\n",
        "\r\n",
        "for j in all_data:\r\n",
        "    print('Loading ', j)\r\n",
        "    csvrows = np.loadtxt(j, delimiter=',')\r\n",
        "    data = np.append(data, csvrows, axis=0)\r\n",
        "\r\n",
        "print(data.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading  ./drive/MyDrive/compsci/all_data.csv\n",
            "(151452, 222)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grp1amW2t9Rv",
        "outputId": "f797d9e8-aca4-4b2d-8015-2f2542e689cd"
      },
      "source": [
        "X = data[:,:-2]\r\n",
        "y = data[:,-2]\r\n",
        "\r\n",
        "inputs = X.reshape(X.shape + (1,1))\r\n",
        "targets = to_categorical(y)\r\n",
        "\r\n",
        "print(inputs.shape)\r\n",
        "print(targets.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(151452, 220, 1, 1)\n",
            "(151452, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPnqnnhdxy9x"
      },
      "source": [
        "def showResults(test, pred):\r\n",
        "    #target_names = ['positive', 'negative']\r\n",
        "    # print(classification_report(test, pred, target_names=target_names))\r\n",
        "    accuracy = accuracy_score(test, pred)\r\n",
        "    precision=precision_score(test, pred, average='weighted')\r\n",
        "    f1Score=f1_score(test, pred, average='weighted') \r\n",
        "    #loss=log_loss(test,pred)\r\n",
        "    print(\"Accuracy  : {}\".format(accuracy))\r\n",
        "    print(\"Precision : {}\".format(precision))\r\n",
        "    print(\"f1Score : {}\".format(f1Score))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW4q39zf03yM",
        "outputId": "877810dc-2e62-4792-efca-b9ba495b659a"
      },
      "source": [
        "# Define the K-fold Cross Validator\r\n",
        "kfold = KFold(n_splits=6, shuffle=True)\r\n",
        "\r\n",
        "# K-fold Cross Validation model evaluation\r\n",
        "fold_no = 1\r\n",
        "\r\n",
        "verbose, epoch, batch_size = 1, 1, 256\r\n",
        "for train, test in kfold.split(inputs, targets):\r\n",
        "\r\n",
        "  lstmmodel = Sequential()\r\n",
        "  lstmmodel.add(LSTM(128, return_sequences=True, input_shape=(inputs[train].shape[1],1)))\r\n",
        "  lstmmodel.add(LSTM(9, return_sequences=True))\r\n",
        "  lstmmodel.add(MaxPooling1D(pool_size=2))\r\n",
        "  lstmmodel.add(Flatten())\r\n",
        "  lstmmodel.add(Dense(512, activation='relu'))\r\n",
        "  lstmmodel.add(Dense(128, activation='relu'))    \r\n",
        "  lstmmodel.add(Dense(32, activation='relu'))\r\n",
        "  lstmmodel.add(Dense(9, activation='softmax'))\r\n",
        "  lstmmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "  \r\n",
        "  # Generate a print\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print(f'Training for fold {fold_no} ...')\r\n",
        "\r\n",
        "  # Fit data to model\r\n",
        "  modelhistory= lstmmodel.fit(inputs[:,:,:,0][train], targets[train], epochs=epoch, \r\n",
        "                             verbose=verbose, validation_split=0.2, \r\n",
        "                             batch_size = batch_size)\r\n",
        "  print(fold_no)\r\n",
        "  lstmpredictions = lstmmodel.predict(inputs[:,:,:,0][test], verbose=1) \r\n",
        "  lstm_predict=np.argmax(lstmpredictions,axis=1)\r\n",
        "  lstm_actual_value=np.argmax(targets[test],axis=1)\r\n",
        "  LSTM_cf_m = showResults(lstm_actual_value, lstm_predict)\r\n",
        "\r\n",
        "  # Increase fold number\r\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "395/395 [==============================] - 21s 42ms/step - loss: 0.3818 - accuracy: 0.9034 - val_loss: 0.5627 - val_accuracy: 0.8516\n",
            "1\n",
            "789/789 [==============================] - 9s 10ms/step\n",
            "Accuracy  : 0.9548371761350131\n",
            "Precision : 0.9542200350061847\n",
            "f1Score : 0.951247262503336\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "395/395 [==============================] - 19s 41ms/step - loss: 0.3986 - accuracy: 0.9037 - val_loss: 0.6624 - val_accuracy: 0.8135\n",
            "2\n",
            "789/789 [==============================] - 9s 10ms/step\n",
            "Accuracy  : 0.9451707471674193\n",
            "Precision : 0.9449687270887588\n",
            "f1Score : 0.9413274787169472\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "395/395 [==============================] - 20s 41ms/step - loss: 0.3839 - accuracy: 0.9013 - val_loss: 0.5159 - val_accuracy: 0.8452\n",
            "3\n",
            "789/789 [==============================] - 9s 10ms/step\n",
            "Accuracy  : 0.9535298312336582\n",
            "Precision : 0.956120090047779\n",
            "f1Score : 0.9522583498680128\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "395/395 [==============================] - 20s 42ms/step - loss: 0.3845 - accuracy: 0.9015 - val_loss: 0.6092 - val_accuracy: 0.8248\n",
            "4\n",
            "789/789 [==============================] - 9s 10ms/step\n",
            "Accuracy  : 0.9473892718485064\n",
            "Precision : 0.9427277000125913\n",
            "f1Score : 0.9438500028906851\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "395/395 [==============================] - 20s 42ms/step - loss: 0.3918 - accuracy: 0.9052 - val_loss: 0.5962 - val_accuracy: 0.7990\n",
            "5\n",
            "789/789 [==============================] - 9s 10ms/step\n",
            "Accuracy  : 0.9418033436336265\n",
            "Precision : 0.9478251846855558\n",
            "f1Score : 0.9431953677239038\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "395/395 [==============================] - 20s 42ms/step - loss: 0.3798 - accuracy: 0.9085 - val_loss: 0.5271 - val_accuracy: 0.8637\n",
            "6\n",
            "789/789 [==============================] - 9s 10ms/step\n",
            "Accuracy  : 0.958204579668806\n",
            "Precision : 0.9611316496834804\n",
            "f1Score : 0.9559200026235984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6OkcqKVt9n2",
        "outputId": "633ee661-b2c6-4a0c-e995-e50ec5b90ca3"
      },
      "source": [
        "# Define the K-fold Cross Validator\r\n",
        "kfold = KFold(n_splits=6, shuffle=True)\r\n",
        "\r\n",
        "# K-fold Cross Validation model evaluation\r\n",
        "fold_no = 1\r\n",
        "\r\n",
        "verbose, epoch, batch_size = 1, 1, 64\r\n",
        "for train, test in kfold.split(inputs, targets):\r\n",
        "\r\n",
        "  # Define the model architecture\r\n",
        "  cnnmodel = Sequential()\r\n",
        "  cnnmodel.add(Conv1D(filters=128, kernel_size=16,padding='same', activation='relu',input_shape=(inputs[train].shape[1],1)))\r\n",
        "  cnnmodel.add(BatchNormalization())\r\n",
        "  cnnmodel.add(Conv1D(filters=32, kernel_size=16,padding='same', activation='relu'))\r\n",
        "  cnnmodel.add(BatchNormalization())\r\n",
        "  cnnmodel.add(Conv1D(filters=9, kernel_size=16,padding='same', activation='relu'))\r\n",
        "  cnnmodel.add(MaxPooling1D(pool_size=2,padding='same'))\r\n",
        "  cnnmodel.add(Flatten())\r\n",
        "  cnnmodel.add(Dense(512, activation='relu'))\r\n",
        "  cnnmodel.add(Dense(128, activation='relu'))\r\n",
        "  cnnmodel.add(Dense(32, activation='relu'))\r\n",
        "  cnnmodel.add(Dense(9, activation='softmax'))\r\n",
        "  cnnmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "  # Generate a print\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print(f'Training for fold {fold_no} ...')\r\n",
        "\r\n",
        "  # Fit data to model\r\n",
        "  modelhistory= cnnmodel.fit(inputs[:,:,:,0][train], targets[train], epochs=epoch, \r\n",
        "                             verbose=verbose, validation_split=0.2, \r\n",
        "                             batch_size = batch_size)\r\n",
        "  print(fold_no)\r\n",
        "  cnnpredictions = cnnmodel.predict(inputs[:,:,:,0][test], verbose=1) \r\n",
        "  cnn_predict=np.argmax(cnnpredictions,axis=1)\r\n",
        "  cnn_actual_value=np.argmax(targets[test],axis=1)\r\n",
        "  CNN_cf_m = showResults(cnn_actual_value, cnn_predict)\r\n",
        "\r\n",
        "  # Increase fold number\r\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "1578/1578 [==============================] - 14s 8ms/step - loss: 0.1701 - accuracy: 0.9564 - val_loss: 0.5807 - val_accuracy: 0.8501\n",
            "1\n",
            "789/789 [==============================] - 2s 2ms/step\n",
            "Accuracy  : 0.9555502733539339\n",
            "Precision : 0.9531197666111557\n",
            "f1Score : 0.950002298046538\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "1578/1578 [==============================] - 13s 8ms/step - loss: 0.1870 - accuracy: 0.9506 - val_loss: 0.6543 - val_accuracy: 0.8320\n",
            "2\n",
            "789/789 [==============================] - 2s 2ms/step\n",
            "Accuracy  : 0.9544806275255526\n",
            "Precision : 0.9530333031294481\n",
            "f1Score : 0.9522118546963653\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "1578/1578 [==============================] - 13s 8ms/step - loss: 0.1923 - accuracy: 0.9494 - val_loss: 0.5041 - val_accuracy: 0.8649\n",
            "3\n",
            "789/789 [==============================] - 2s 2ms/step\n",
            "Accuracy  : 0.9587592108390778\n",
            "Precision : 0.9547689107245366\n",
            "f1Score : 0.9543012418316527\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "1578/1578 [==============================] - 14s 8ms/step - loss: 0.2096 - accuracy: 0.9489 - val_loss: 0.8454 - val_accuracy: 0.8205\n",
            "4\n",
            "789/789 [==============================] - 2s 2ms/step\n",
            "Accuracy  : 0.9482212186039141\n",
            "Precision : 0.9520338583142472\n",
            "f1Score : 0.9480820828078732\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "1578/1578 [==============================] - 14s 8ms/step - loss: 0.1815 - accuracy: 0.9513 - val_loss: 0.9988 - val_accuracy: 0.8030\n",
            "5\n",
            "789/789 [==============================] - 2s 2ms/step\n",
            "Accuracy  : 0.9466365581174233\n",
            "Precision : 0.9438381878092543\n",
            "f1Score : 0.9430067643057561\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "1578/1578 [==============================] - 13s 8ms/step - loss: 0.1789 - accuracy: 0.9546 - val_loss: 0.5757 - val_accuracy: 0.8639\n",
            "6\n",
            "789/789 [==============================] - 2s 2ms/step\n",
            "Accuracy  : 0.9597100071309722\n",
            "Precision : 0.9569755397318355\n",
            "f1Score : 0.9542619451311515\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}