{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cross_val_keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExTXqOFftnrL"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from pylab import rcParams\r\n",
        "from scipy.stats.stats import kendalltau\r\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\r\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from sklearn.utils import class_weight\r\n",
        "from sklearn.metrics import log_loss\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import Input\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\r\n",
        "from tensorflow.keras.models import Model, load_model\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Conv1D, Conv1DTranspose\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras.layers import LSTM, Masking\r\n",
        "from tensorflow.keras.layers import MaxPooling1D, GlobalAveragePooling1D\r\n",
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "from tensorflow.keras import activations\r\n",
        "sns.set()\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxRganT3t1ZJ",
        "outputId": "f0dfd88d-97b0-43c0-e103-13b54241e1c1"
      },
      "source": [
        "import numpy as np\r\n",
        "import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from scipy import *\r\n",
        "\r\n",
        "data = np.empty(shape=[0, 222])\r\n",
        "\r\n",
        "all_data = glob.glob('./drive/MyDrive/compsci/all_data.csv')\r\n",
        "\r\n",
        "for j in all_data:\r\n",
        "    print('Loading ', j)\r\n",
        "    csvrows = np.loadtxt(j, delimiter=',')\r\n",
        "    data = np.append(data, csvrows, axis=0)\r\n",
        "\r\n",
        "print(data.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading  ./drive/MyDrive/compsci/all_data.csv\n",
            "(151452, 222)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grp1amW2t9Rv",
        "outputId": "89b5efeb-f0f9-4acc-ffd5-79b6a6cfcdd3"
      },
      "source": [
        "X = data[:,:-2]\r\n",
        "y = data[:,-2]\r\n",
        "\r\n",
        "inputs = X.reshape(X.shape + (1,1))\r\n",
        "# targets = to_categorical(y)\r\n",
        "targets = (y)\r\n",
        "\r\n",
        "print(inputs.shape)\r\n",
        "print(targets.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(151452, 220, 1, 1)\n",
            "(151452,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW4q39zf03yM",
        "outputId": "53c069d3-aef9-463d-b31d-bde376b7a3d2"
      },
      "source": [
        "# Define the K-fold Cross Validator\r\n",
        "kfold = StratifiedKFold(n_splits=6, shuffle=False)\r\n",
        "\r\n",
        "# K-fold Cross Validation model evaluation\r\n",
        "fold_no = 1\r\n",
        "\r\n",
        "verbose, epoch, batch_size = 1, 1, 256\r\n",
        "for train, test in kfold.split(inputs, targets):\r\n",
        "  targets = to_categorical(y)\r\n",
        "  lstmmodel = Sequential()\r\n",
        "  lstmmodel.add(LSTM(128, return_sequences=True, input_shape=(inputs[train].shape[1],1)))\r\n",
        "  lstmmodel.add(LSTM(9, return_sequences=True))\r\n",
        "  lstmmodel.add(MaxPooling1D(pool_size=2))\r\n",
        "  lstmmodel.add(Flatten())\r\n",
        "  lstmmodel.add(Dense(512, activation='relu'))\r\n",
        "  lstmmodel.add(Dense(128, activation='relu'))    \r\n",
        "  lstmmodel.add(Dense(32, activation='relu'))\r\n",
        "  lstmmodel.add(Dense(9, activation='softmax'))\r\n",
        "  lstmmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "  \r\n",
        "  # Generate a print\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print(f'Training for fold {fold_no} ...')\r\n",
        "\r\n",
        "  # Fit data to model\r\n",
        "  modelhistory= lstmmodel.fit(inputs[:,:,:,0][train], targets[train], epochs=epoch, \r\n",
        "                             verbose=verbose, validation_split=0.2, \r\n",
        "                             batch_size = batch_size)\r\n",
        "  print(fold_no)\r\n",
        "  lstmpredictions = lstmmodel.predict(inputs[:,:,:,0][test], verbose=1) \r\n",
        "  lstm_predict=np.argmax(lstmpredictions,axis=1)\r\n",
        "  lstm_actual_value=np.argmax(targets[test],axis=1)\r\n",
        "  lstmmetrics = metrics.classification_report(lstm_actual_value, lstm_predict, digits=3)\r\n",
        "  print(lstmmetrics, 'lstm metrics')\r\n",
        "  # Increase fold number\r\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "395/395 [==============================] - 42s 97ms/step - loss: 0.3709 - accuracy: 0.9061 - val_loss: 0.8079 - val_accuracy: 0.7826\n",
            "1\n",
            "789/789 [==============================] - 20s 25ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.972     0.876     0.922     19062\n",
            "           2      0.965     0.972     0.968      1098\n",
            "           3      0.568     0.992     0.723      1698\n",
            "           4      0.301     0.734     0.427       811\n",
            "           5      0.340     0.190     0.244       522\n",
            "           6      0.618     0.453     0.523       139\n",
            "           7      0.897     0.402     0.555       281\n",
            "           8      0.971     0.902     0.935      1631\n",
            "\n",
            "    accuracy                          0.863     25242\n",
            "   macro avg      0.704     0.690     0.662     25242\n",
            "weighted avg      0.907     0.863     0.875     25242\n",
            " lstm metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "395/395 [==============================] - 42s 97ms/step - loss: 0.3966 - accuracy: 0.9039 - val_loss: 0.6773 - val_accuracy: 0.8281\n",
            "2\n",
            "789/789 [==============================] - 20s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.964     0.935     0.949     19062\n",
            "           2      0.493     1.000     0.660      1098\n",
            "           3      0.997     0.928     0.962      1698\n",
            "           4      0.952     0.783     0.859       812\n",
            "           5      0.887     0.241     0.380       522\n",
            "           6      0.974     0.800     0.878       140\n",
            "           7      0.549     0.957     0.698       280\n",
            "           8      0.992     0.943     0.967      1630\n",
            "\n",
            "    accuracy                          0.918     25242\n",
            "   macro avg      0.851     0.823     0.794     25242\n",
            "weighted avg      0.941     0.918     0.921     25242\n",
            " lstm metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "395/395 [==============================] - 41s 97ms/step - loss: 0.3726 - accuracy: 0.9081 - val_loss: 0.5936 - val_accuracy: 0.8430\n",
            "3\n",
            "789/789 [==============================] - 20s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.968     0.857     0.909     19061\n",
            "           2      0.499     0.996     0.665      1098\n",
            "           3      0.959     0.979     0.969      1698\n",
            "           4      0.328     0.659     0.438       812\n",
            "           5      0.198     0.191     0.194       523\n",
            "           6      0.275     0.736     0.401       140\n",
            "           7      0.691     0.718     0.704       280\n",
            "           8      0.985     0.989     0.987      1630\n",
            "\n",
            "    accuracy                          0.858     25242\n",
            "   macro avg      0.613     0.766     0.658     25242\n",
            "weighted avg      0.905     0.858     0.873     25242\n",
            " lstm metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "395/395 [==============================] - 42s 97ms/step - loss: 0.3809 - accuracy: 0.9038 - val_loss: 0.8663 - val_accuracy: 0.7743\n",
            "4\n",
            "789/789 [==============================] - 20s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.961     0.737     0.834     19061\n",
            "           2      0.962     0.994     0.978      1098\n",
            "           3      0.954     0.839     0.893      1698\n",
            "           4      0.532     0.586     0.558       812\n",
            "           5      0.000     0.002     0.001       523\n",
            "           6      0.048     0.857     0.091       140\n",
            "           7      0.618     0.929     0.742       280\n",
            "           8      0.934     0.999     0.966      1630\n",
            "\n",
            "    accuracy                          0.755     25242\n",
            "   macro avg      0.626     0.743     0.633     25242\n",
            "weighted avg      0.916     0.755     0.822     25242\n",
            " lstm metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "395/395 [==============================] - 41s 97ms/step - loss: 0.3448 - accuracy: 0.9151 - val_loss: 0.7078 - val_accuracy: 0.8289\n",
            "5\n",
            "789/789 [==============================] - 20s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.953     0.966     0.960     19061\n",
            "           2      0.956     0.946     0.951      1098\n",
            "           3      0.950     0.897     0.923      1699\n",
            "           4      0.852     0.730     0.786       811\n",
            "           5      0.006     0.006     0.006       522\n",
            "           6      0.936     0.633     0.755       139\n",
            "           7      0.519     0.530     0.525       281\n",
            "           8      0.978     0.982     0.980      1631\n",
            "\n",
            "    accuracy                          0.927     25242\n",
            "   macro avg      0.769     0.711     0.736     25242\n",
            "weighted avg      0.927     0.927     0.927     25242\n",
            " lstm metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "395/395 [==============================] - 42s 97ms/step - loss: 0.3866 - accuracy: 0.9058 - val_loss: 0.6604 - val_accuracy: 0.8337\n",
            "6\n",
            "789/789 [==============================] - 19s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.865     0.979     0.919     19061\n",
            "           2      0.908     0.990     0.947      1098\n",
            "           3      0.511     0.041     0.075      1699\n",
            "           4      0.298     0.672     0.413       811\n",
            "           5      0.000     0.000     0.000       522\n",
            "           6      0.800     0.374     0.510       139\n",
            "           7      0.079     0.032     0.046       281\n",
            "           8      0.986     0.084     0.155      1631\n",
            "\n",
            "    accuracy                          0.815     25242\n",
            "   macro avg      0.556     0.397     0.383     25242\n",
            "weighted avg      0.806     0.815     0.766     25242\n",
            " lstm metrics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASM-uR-hrKPZ",
        "outputId": "43fda0e4-277e-4325-ff06-99bad45364fb"
      },
      "source": [
        "X = data[:,:-2]\r\n",
        "y = data[:,-2]\r\n",
        "\r\n",
        "inputs = X.reshape(X.shape + (1,1))\r\n",
        "# targets = to_categorical(y)\r\n",
        "targets = (y)\r\n",
        "\r\n",
        "print(inputs.shape)\r\n",
        "print(targets.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(151452, 220, 1, 1)\n",
            "(151452,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6OkcqKVt9n2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ec8d1c-e9e3-459e-f2a0-d946104504b6"
      },
      "source": [
        "# Define the K-fold Cross Validator\r\n",
        "kfold = StratifiedKFold(n_splits=6, shuffle=True)\r\n",
        "\r\n",
        "# K-fold Cross Validation model evaluation\r\n",
        "fold_no = 1\r\n",
        "\r\n",
        "verbose, epoch, batch_size = 1, 1, 64\r\n",
        "for train, test in kfold.split(inputs, targets):\r\n",
        "  targets = to_categorical(y)\r\n",
        "  # Define the model architecture\r\n",
        "  cnnmodel = Sequential()\r\n",
        "  cnnmodel.add(Conv1D(filters=128, kernel_size=16,padding='same', activation='relu',input_shape=(inputs[train].shape[1],1)))\r\n",
        "  cnnmodel.add(BatchNormalization())\r\n",
        "  cnnmodel.add(Conv1D(filters=32, kernel_size=16,padding='same', activation='relu'))\r\n",
        "  cnnmodel.add(BatchNormalization())\r\n",
        "  cnnmodel.add(Conv1D(filters=9, kernel_size=16,padding='same', activation='relu'))\r\n",
        "  cnnmodel.add(MaxPooling1D(pool_size=2,padding='same'))\r\n",
        "  cnnmodel.add(Flatten())\r\n",
        "  cnnmodel.add(Dense(512, activation='relu'))\r\n",
        "  cnnmodel.add(Dense(128, activation='relu'))\r\n",
        "  cnnmodel.add(Dense(32, activation='relu'))\r\n",
        "  cnnmodel.add(Dense(9, activation='softmax'))\r\n",
        "  cnnmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "  # Generate a print\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print(f'Training for fold {fold_no} ...')\r\n",
        "\r\n",
        "  # Fit data to model\r\n",
        "  modelhistory= cnnmodel.fit(inputs[:,:,:,0][train], targets[train], epochs=epoch, \r\n",
        "                             verbose=verbose, validation_split=0.2, \r\n",
        "                             batch_size = batch_size)\r\n",
        "  print(fold_no)\r\n",
        "  cnnpredictions = cnnmodel.predict(inputs[:,:,:,0][test], verbose=1) \r\n",
        "  cnn_predict=np.argmax(cnnpredictions,axis=1)\r\n",
        "  cnn_actual_value=np.argmax(targets[test],axis=1)\r\n",
        "  cnnmetrics = metrics.classification_report(cnn_actual_value, cnn_predict, digits=3)\r\n",
        "  print(cnnmetrics, 'CNN metrics')\r\n",
        "  # Increase fold number\r\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "1578/1578 [==============================] - 24s 15ms/step - loss: 0.1861 - accuracy: 0.9505 - val_loss: 0.5266 - val_accuracy: 0.8420\n",
            "1\n",
            "789/789 [==============================] - 2s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.977     0.975     0.976     19062\n",
            "           2      0.871     0.993     0.928      1098\n",
            "           3      0.953     0.961     0.957      1698\n",
            "           4      0.716     0.869     0.785       811\n",
            "           5      0.733     0.241     0.363       522\n",
            "           6      0.877     0.460     0.604       139\n",
            "           7      0.640     0.872     0.738       281\n",
            "           8      0.987     0.999     0.993      1631\n",
            "\n",
            "    accuracy                          0.954     25242\n",
            "   macro avg      0.844     0.796     0.793     25242\n",
            "weighted avg      0.954     0.954     0.950     25242\n",
            " CNN metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "1578/1578 [==============================] - 24s 15ms/step - loss: 0.2189 - accuracy: 0.9435 - val_loss: 0.3722 - val_accuracy: 0.9001\n",
            "2\n",
            "789/789 [==============================] - 3s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.982     0.991     0.987     19062\n",
            "           2      1.000     0.990     0.995      1098\n",
            "           3      0.968     0.982     0.975      1698\n",
            "           4      0.750     0.821     0.784       812\n",
            "           5      0.865     0.220     0.351       522\n",
            "           6      0.684     0.757     0.719       140\n",
            "           7      0.841     0.832     0.837       280\n",
            "           8      0.939     0.999     0.968      1630\n",
            "\n",
            "    accuracy                          0.967     25242\n",
            "   macro avg      0.879     0.824     0.827     25242\n",
            "weighted avg      0.966     0.967     0.962     25242\n",
            " CNN metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "1578/1578 [==============================] - 24s 15ms/step - loss: 0.1742 - accuracy: 0.9550 - val_loss: 0.8554 - val_accuracy: 0.8230\n",
            "3\n",
            "789/789 [==============================] - 2s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.957     0.984     0.970     19061\n",
            "           2      0.986     0.988     0.987      1098\n",
            "           3      0.876     0.834     0.854      1698\n",
            "           4      0.907     0.780     0.838       812\n",
            "           5      0.713     0.237     0.356       523\n",
            "           6      0.745     0.521     0.613       140\n",
            "           7      0.815     0.946     0.876       280\n",
            "           8      0.993     0.994     0.993      1630\n",
            "\n",
            "    accuracy                          0.950     25242\n",
            "   macro avg      0.874     0.786     0.811     25242\n",
            "weighted avg      0.946     0.950     0.945     25242\n",
            " CNN metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "1578/1578 [==============================] - 25s 15ms/step - loss: 0.1992 - accuracy: 0.9483 - val_loss: 0.5603 - val_accuracy: 0.8131\n",
            "4\n",
            "789/789 [==============================] - 3s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.979     0.965     0.972     19061\n",
            "           2      0.956     0.996     0.976      1098\n",
            "           3      0.937     0.952     0.945      1698\n",
            "           4      0.759     0.818     0.787       812\n",
            "           5      0.605     0.308     0.408       523\n",
            "           6      0.833     0.679     0.748       140\n",
            "           7      0.364     0.946     0.525       280\n",
            "           8      0.990     0.973     0.981      1630\n",
            "\n",
            "    accuracy                          0.946     25242\n",
            "   macro avg      0.803     0.830     0.793     25242\n",
            "weighted avg      0.954     0.946     0.947     25242\n",
            " CNN metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "1578/1578 [==============================] - 24s 15ms/step - loss: 0.1960 - accuracy: 0.9479 - val_loss: 0.5714 - val_accuracy: 0.8729\n",
            "5\n",
            "789/789 [==============================] - 3s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.964     0.989     0.976     19061\n",
            "           2      0.951     0.991     0.971      1098\n",
            "           3      0.914     0.926     0.920      1699\n",
            "           4      0.896     0.767     0.827       811\n",
            "           5      0.806     0.303     0.440       522\n",
            "           6      0.895     0.612     0.726       139\n",
            "           7      0.949     0.662     0.780       281\n",
            "           8      0.985     0.998     0.991      1631\n",
            "\n",
            "    accuracy                          0.958     25242\n",
            "   macro avg      0.920     0.781     0.829     25242\n",
            "weighted avg      0.956     0.958     0.954     25242\n",
            " CNN metrics\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "1578/1578 [==============================] - 24s 15ms/step - loss: 0.1886 - accuracy: 0.9480 - val_loss: 0.4945 - val_accuracy: 0.8570\n",
            "6\n",
            "789/789 [==============================] - 3s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.975     0.981     0.978     19061\n",
            "           2      0.971     0.994     0.982      1098\n",
            "           3      0.956     0.955     0.956      1699\n",
            "           4      0.729     0.864     0.791       811\n",
            "           5      0.742     0.314     0.441       522\n",
            "           6      0.989     0.655     0.788       139\n",
            "           7      0.735     0.868     0.796       281\n",
            "           8      0.984     0.994     0.989      1631\n",
            "\n",
            "    accuracy                          0.960     25242\n",
            "   macro avg      0.885     0.828     0.840     25242\n",
            "weighted avg      0.959     0.960     0.957     25242\n",
            " CNN metrics\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}