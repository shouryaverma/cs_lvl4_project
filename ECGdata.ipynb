{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import glob\n",
    "from wfdb import processing\n",
    "import scipy\n",
    "from scipy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# record = wfdb.rdrecord('./mit-bih/100', sampto=2000)\n",
    "# wfdb.plot_wfdb(record, title='Record 100',figsize=(20,5))\n",
    "# display(record.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_files = glob.glob('./mit-bih/*.atr')\n",
    "# data_files = [i[:-4] for i in data_files]\n",
    "# data_files.sort()\n",
    "# print(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = ['N','R','L','V','A','E']\n",
    "#record_nums =[]\n",
    "#record_names = []\n",
    "#num_beats =[]\n",
    "\n",
    "#for i in range(len(data_files)):\n",
    "#    signals, fields = wfdb.rdsamp(data_files[i])\n",
    "#    annotation = wfdb.rdann(data_files[i], 'atr')\n",
    "#    record_nums.append(i)\n",
    "##    record_names.append(data_files[i])\n",
    "#    for j in classes:\n",
    "#        ids = np.in1d(annotation.symbol, j)\n",
    "#        beats = annotation.sample[ids]\n",
    "#        num_beats.append(len(beats))\n",
    "   \n",
    "#n_vals = num_beats[::6]\n",
    "#r_vals = num_beats[1::6]\n",
    "#l_vals = num_beats[2::6]\n",
    "#v_vals = num_beats[3::6]\n",
    "#a_vals = num_beats[4::6]\n",
    "#e_vals = num_beats[5::6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wfdb as wf\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# from matplotlib import pyplot as plt\n",
    "# from biosppy.signals import ecg\n",
    "# from scipy import signal\n",
    "\n",
    "# def extract_data():\n",
    "#     data_files = glob.glob('./mit-bih/*.atr')\n",
    "#     data_files = [i[:-4] for i in data_files]\n",
    "#     data_files.sort()\n",
    "#     return data_files\n",
    "\n",
    "# files = extract_data()\n",
    "# i=0\n",
    "\n",
    "# good_beats =['N','L','R','B','A','a','J','S','V','r',\n",
    "#              'F','e','j','n','E','/','f','Q','?']\n",
    "# list_anns = []\n",
    "\n",
    "# for i in range(len(files)):\n",
    "#     datfile = files[i]\n",
    "#     record = wf.rdsamp(datfile)\n",
    "#     ann = wf.rdann(datfile, 'atr')\n",
    "#     list_anns.extend(ann.symbol)\n",
    "\n",
    "# dict_anns = {}\n",
    "\n",
    "# for i in list_anns:\n",
    "#     dict_anns[i] = dict_anns.get(i,0)+1\n",
    "    \n",
    "# dict_anns = {k:v for k,v in dict_anns.items() if k in good_beats}\n",
    "\n",
    "# print(dict_anns.values())\n",
    "\n",
    "# plt.figure(figsize=(16,8))\n",
    "\n",
    "# xlocs, xlabs = plt.xticks()\n",
    "# barplt = plt.bar(list(dict_anns.keys()),dict_anns.values(),width = .6)\n",
    "# xlocs = [j for j in dict_anns.keys()]\n",
    "# ylabs = [j for j in dict_anns.values()]\n",
    "\n",
    "# plt.title('Annotation Distribution')\n",
    "# plt.xlabel('Annotations')\n",
    "# plt.ylabel('Counts')\n",
    "\n",
    "# for bar in barplt:\n",
    "#     yval = bar.get_height()\n",
    "#     plt.text(bar.get_x(), yval+1000, yval)\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wfdb as wf\n",
    "# import glob\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "# from biosppy.signals import ecg\n",
    "# from scipy import signal\n",
    "\n",
    "# def extract_data():\n",
    "#     data_files = glob.glob('./mit-bih/*.atr')\n",
    "#     data_files = [i[:-4] for i in data_files]\n",
    "#     data_files.sort()\n",
    "#     return data_files\n",
    "\n",
    "# files = extract_data()\n",
    "\n",
    "# i=4 #file number 0-47\n",
    "# channel_num=1 # There are 2 channels\n",
    "# samplestart =0 # Start of the sample in the file.\n",
    "# samplesize=3000 # Number of readings (360 per second)\n",
    "# sampleend = samplestart + samplesize #End of sample in the file.\n",
    "\n",
    "# datfile = files[i]\n",
    "# record = wf.rdsamp(datfile)\n",
    "# ann = wf.rdann(datfile, 'atr')\n",
    "\n",
    "# # Get data and anns for the samples selected below.\n",
    "# channel = record[0][samplestart:sampleend, channel_num]\n",
    "\n",
    "# # Plot the heart beats. Time scale is number of readings\n",
    "# # divided by sampling frequency.\n",
    "# time_scale = (np.arange(samplesize, dtype = 'float') + samplestart) / record[1].get('fs')\n",
    "# plt.figure(figsize=(15,5))\n",
    "# plt.plot(time_scale, channel)\n",
    "\n",
    "# # Extract anns.\n",
    "# location_p = np.logical_and(ann.sample >= samplestart, ann.sample < sampleend)\n",
    "# anns = ann.sample[location_p] - samplestart\n",
    "# annotypes = np.array(ann.symbol)\n",
    "# annotypes = annotypes[location_p]\n",
    "\n",
    "# # Plot the anns.\n",
    "# annotimes = time_scale[anns]\n",
    "# plt.plot(annotimes, np.ones_like(annotimes) * channel.max() * 1.4, 'ro')\n",
    "\n",
    "# # ann codes.\n",
    "# for ind, annot in enumerate(anns):\n",
    "#     plt.annotate(annotypes[ind], xy = (time_scale[annot], channel.max() * 1.1))\n",
    "\n",
    "# plt.xlim([samplestart / record[1].get('fs'), (sampleend / record[1].get('fs')) + 1])\n",
    "# plt.xlabel('Offset')\n",
    "# plt.ylabel(record[1].get('sig_name')[channel_num])\n",
    "# plt.title('record: '+datfile[-3:]+'    channel: '+record[1].get('sig_name')[channel_num])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files:  48\n",
      "Loading file: ./mit-bih\\100\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2274\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\100_MLII.csv\n",
      "    ECG channel type: V5\n",
      "    Generating  ./mit-bih\\100_V5.csv\n",
      "Loading file: ./mit-bih\\101\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1874\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\101_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\101_V1.csv\n",
      "Loading file: ./mit-bih\\102\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2192\n",
      "    ECG channel type: V5\n",
      "    Generating  ./mit-bih\\102_V5.csv\n",
      "    ECG channel type: V2\n",
      "    Generating  ./mit-bih\\102_V2.csv\n",
      "Loading file: ./mit-bih\\103\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2091\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\103_MLII.csv\n",
      "    ECG channel type: V2\n",
      "    Generating  ./mit-bih\\103_V2.csv\n",
      "Loading file: ./mit-bih\\104\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2311\n",
      "    ECG channel type: V5\n",
      "    Generating  ./mit-bih\\104_V5.csv\n",
      "    ECG channel type: V2\n",
      "    Generating  ./mit-bih\\104_V2.csv\n",
      "Loading file: ./mit-bih\\105\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2691\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\105_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\105_V1.csv\n",
      "Loading file: ./mit-bih\\106\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2098\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\106_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\106_V1.csv\n",
      "Loading file: ./mit-bih\\107\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2140\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\107_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\107_V1.csv\n",
      "Loading file: ./mit-bih\\108\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1824\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\108_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\108_V1.csv\n",
      "Loading file: ./mit-bih\\109\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2535\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\109_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\109_V1.csv\n",
      "Loading file: ./mit-bih\\111\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2133\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\111_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\111_V1.csv\n",
      "Loading file: ./mit-bih\\112\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2550\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\112_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\112_V1.csv\n",
      "Loading file: ./mit-bih\\113\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1796\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\113_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\113_V1.csv\n",
      "Loading file: ./mit-bih\\114\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1890\n",
      "    ECG channel type: V5\n",
      "    Generating  ./mit-bih\\114_V5.csv\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\114_MLII.csv\n",
      "Loading file: ./mit-bih\\115\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1962\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\115_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\115_V1.csv\n",
      "Loading file: ./mit-bih\\116\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2421\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\116_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\116_V1.csv\n",
      "Loading file: ./mit-bih\\117\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1539\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\117_MLII.csv\n",
      "    ECG channel type: V2\n",
      "    Generating  ./mit-bih\\117_V2.csv\n",
      "Loading file: ./mit-bih\\118\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2301\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\118_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\118_V1.csv\n",
      "Loading file: ./mit-bih\\119\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2094\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\119_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\119_V1.csv\n",
      "Loading file: ./mit-bih\\121\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1876\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\121_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\121_V1.csv\n",
      "Loading file: ./mit-bih\\122\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2479\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\122_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\122_V1.csv\n",
      "Loading file: ./mit-bih\\123\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1519\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\123_MLII.csv\n",
      "    ECG channel type: V5\n",
      "    Generating  ./mit-bih\\123_V5.csv\n",
      "Loading file: ./mit-bih\\124\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1634\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\124_MLII.csv\n",
      "    ECG channel type: V4\n",
      "    Generating  ./mit-bih\\124_V4.csv\n",
      "Loading file: ./mit-bih\\200\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2792\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\200_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\200_V1.csv\n",
      "Loading file: ./mit-bih\\201\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2039\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\201_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\201_V1.csv\n",
      "Loading file: ./mit-bih\\202\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2146\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\202_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\202_V1.csv\n",
      "Loading file: ./mit-bih\\203\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 3108\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\203_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\203_V1.csv\n",
      "Loading file: ./mit-bih\\205\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2672\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\205_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\205_V1.csv\n",
      "Loading file: ./mit-bih\\207\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2385\n",
      "    ECG channel type: MLII\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Generating  ./mit-bih\\207_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\207_V1.csv\n",
      "Loading file: ./mit-bih\\208\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 3040\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\208_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\208_V1.csv\n",
      "Loading file: ./mit-bih\\209\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 3052\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\209_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\209_V1.csv\n",
      "Loading file: ./mit-bih\\210\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2685\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\210_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\210_V1.csv\n",
      "Loading file: ./mit-bih\\212\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2763\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\212_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\212_V1.csv\n",
      "Loading file: ./mit-bih\\213\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 3294\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\213_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\213_V1.csv\n",
      "Loading file: ./mit-bih\\214\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2297\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\214_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\214_V1.csv\n",
      "Loading file: ./mit-bih\\215\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 3400\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\215_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\215_V1.csv\n",
      "Loading file: ./mit-bih\\217\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2280\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\217_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\217_V1.csv\n",
      "Loading file: ./mit-bih\\219\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2312\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\219_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\219_V1.csv\n",
      "Loading file: ./mit-bih\\220\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2069\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\220_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\220_V1.csv\n",
      "Loading file: ./mit-bih\\221\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2462\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\221_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\221_V1.csv\n",
      "Loading file: ./mit-bih\\222\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2634\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\222_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\222_V1.csv\n",
      "Loading file: ./mit-bih\\223\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2643\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\223_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\223_V1.csv\n",
      "Loading file: ./mit-bih\\228\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2141\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\228_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\228_V1.csv\n",
      "Loading file: ./mit-bih\\230\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2466\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\230_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\230_V1.csv\n",
      "Loading file: ./mit-bih\\231\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2011\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\231_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\231_V1.csv\n",
      "Loading file: ./mit-bih\\232\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 1816\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\232_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\232_V1.csv\n",
      "Loading file: ./mit-bih\\233\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 3152\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\233_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\233_V1.csv\n",
      "Loading file: ./mit-bih\\234\n",
      "    Sampling frequency used for this record: 360\n",
      "    Shape of loaded data array: (650000, 2)\n",
      "    Number of loaded annotations: 2764\n",
      "    ECG channel type: MLII\n",
      "    Generating  ./mit-bih\\234_MLII.csv\n",
      "    ECG channel type: V1\n",
      "    Generating  ./mit-bih\\234_V1.csv\n"
     ]
    }
   ],
   "source": [
    "# import wfdb as wf\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# from matplotlib import pyplot as plt\n",
    "# from biosppy.signals import ecg\n",
    "# from scipy import signal\n",
    "\n",
    "# def extract_data():\n",
    "#     data_files = glob.glob('./mit-bih/*.atr')\n",
    "#     data_files = [i[:-4] for i in data_files]\n",
    "#     data_files.sort()\n",
    "#     return data_files\n",
    "\n",
    "# records = extract_data()\n",
    "# print('Total files: ', len(records))\n",
    "\n",
    "# # Instead of using the annotations to find the beats, we will\n",
    "# # use R-peak detection instead. The reason for this is so that\n",
    "# # the same logic can be used to analyze new and un-annotated\n",
    "# # ECG data. We use the annotations here only to classify the\n",
    "# # beat as either Normal or Abnormal and to train the model.\n",
    "# # Reference:\n",
    "# # https://physionet.org/physiobank/database/html/mitdbdir/intro.htm\n",
    "\n",
    "# good_beats = ['N','L','R','B','A','a','J','S','V','r',\n",
    "#              'F','e','j','n','E','/','f','Q','?']\n",
    "\n",
    "# # Loop through each input file. Each file contains one\n",
    "# # record of ECG readings, sampled at 360 readings per\n",
    "# # second.\n",
    "\n",
    "\n",
    "# for path in records:\n",
    "#     pathpts = path.split('/')\n",
    "#     fn = pathpts[-1]\n",
    "#     print('Loading file:', path)\n",
    "\n",
    "#     # Read in the data\n",
    "#     record = wf.rdsamp(path)\n",
    "#     annotation = wf.rdann(path, 'atr')\n",
    "\n",
    "#     # Print some meta informations\n",
    "#     print('    Sampling frequency used for this record:', record[1].get('fs'))\n",
    "#     print('    Shape of loaded data array:', record[0].shape)\n",
    "#     print('    Number of loaded annotations:', len(annotation.num))\n",
    "    \n",
    "#     # Get the ECG values from the file.\n",
    "#     data = record[0].transpose()\n",
    "\n",
    "#     # Generate the classifications based on the annotations.\n",
    "#     # 0.0 = undetermined\n",
    "#     # 1.0 = normal\n",
    "#     # 2.0 = LBBBB\n",
    "#     # 3.0 = RBBBB\n",
    "#     # 4.0 = Premature Ventricular contraction\n",
    "#     # 5.0 = Atrial Premature beat\n",
    "#     # 6.0 = Fusion ventricular normal beat\n",
    "#     # 7.0 = Fusion of paced and normal beat\n",
    "#     # 8.0 = paced beat\n",
    "    \n",
    "#     clas = np.array(annotation.symbol)\n",
    "#     rate = np.zeros_like(clas, dtype='float')\n",
    "#     for clasid, clasval in enumerate(clas):\n",
    "#         if (clasval == 'N'):\n",
    "#             rate[clasid] = 1.0 # Normal\n",
    "#         elif (clasval == 'L'):\n",
    "#             rate[clasid] = 2.0 # LBBBB\n",
    "#         elif (clasval == 'R'):\n",
    "#             rate[clasid] = 3.0 # RBBBB\n",
    "#         elif (clasval == 'V'):\n",
    "#             rate[clasid] = 4.0 # Premature Ventricular contraction\n",
    "#         elif (clasval == 'A'):\n",
    "#             rate[clasid] = 5.0 # Atrial Premature beat\n",
    "#         elif (clasval == 'F'):\n",
    "#             rate[clasid] = 6.0 # Fusion ventricular normal beat\n",
    "#         elif (clasval == 'f'):\n",
    "#             rate[clasid] = 7.0 # Fusion of paced and normal beat\n",
    "#         elif (clasval == '/'):\n",
    "#             rate[clasid] = 8.0 # paced beat\n",
    "            \n",
    "#     rates = np.zeros_like(data[0], dtype='float')\n",
    "#     rates[annotation.sample] = rate\n",
    "    \n",
    "#     indices = np.arange(data[0].size, dtype='int')\n",
    "\n",
    "#     # Manipulate both channels\n",
    "#     for channelid, channel in enumerate(data):\n",
    "#         chname = record[1].get('sig_name')[channelid]\n",
    "#         print('    ECG channel type:', chname)\n",
    "        \n",
    "#         # Find rpeaks in the ECG data. Most should match with\n",
    "#         # the annotations.\n",
    "#         out = ecg.ecg(signal=channel, sampling_rate=360, show=False)\n",
    "#         rpeaks = np.zeros_like(channel, dtype='float')\n",
    "#         rpeaks[out['rpeaks']] = 1.0\n",
    "        \n",
    "#         discard_beats = np.array([0])\n",
    "\n",
    "#         # Split into individual heartbeats. For each heartbeat\n",
    "#         # record, append classification (normal/abnormal).\n",
    "#         beats = np.split(channel, out['rpeaks'])\n",
    "#         for ind, ind_val in enumerate(out['rpeaks']):\n",
    "#             beat_start = ind == 0\n",
    "#             beat_end = ind == len(beats) - 1\n",
    "\n",
    "#             # Skip start and end beat.\n",
    "#             if (beat_start or beat_end):\n",
    "#                 continue\n",
    "\n",
    "#             # Get the classification value that is on\n",
    "#             # or near the position of the rpeak index.\n",
    "#             from_ind = 0 if ind_val < 10 else ind_val - 10\n",
    "#             to_ind = ind_val + 10\n",
    "#             clasval = rates[from_ind:to_ind].max()\n",
    "            \n",
    "#             # Skip beat if there is no classification.\n",
    "#             if (clasval == 0.0):\n",
    "#                 discard_beats = np.append(discard_beats, ind)\n",
    "#                 continue\n",
    "\n",
    "#             # Append some extra readings from next beat.\n",
    "#             beats[ind] = np.append(beats[ind][80:], beats[ind+1][0:180])\n",
    "\n",
    "#             # Normalize the data\n",
    "#             #beats[ind] = (beats[ind] - beats[ind].min()) / (beats[ind].max() - beats[ind].min())\n",
    "            \n",
    "#             # Standardize the data\n",
    "#             beats[ind] = ((beats[ind] - np.mean(beats[ind])) / np.std(beats[ind]))\n",
    "            \n",
    "#             # Resample from 360Hz to 125Hz\n",
    "#             newsize = int(beats[ind].size * 125 / 360)\n",
    "#             beats[ind] = signal.resample(beats[ind], newsize)\n",
    "\n",
    "#             # Skipping records that are too long.\n",
    "#             if (beats[ind].size > 187):\n",
    "#                 discard_beats = np.append(discard_beats, ind)\n",
    "#                 continue\n",
    "\n",
    "#             # Pad with zeroes.\n",
    "#             zerocount = 187 - beats[ind].size\n",
    "#             beats[ind] = np.pad(beats[ind], (0, zerocount), 'constant', constant_values=(0.0, 0.0))\n",
    "\n",
    "#             # Append the classification to the beat data.\n",
    "#             beats[ind] = np.append(beats[ind], clasval)\n",
    "            \n",
    "#             # Append the record number to the beat data.\n",
    "#             beats[ind] = np.append(beats[ind], fn[-3:])\n",
    "\n",
    "#         discard_beats = np.append(discard_beats, len(beats)-1)\n",
    "\n",
    "#         # Remove first and last beats and the ones without classification.\n",
    "#         beats = np.delete(beats, discard_beats)\n",
    "\n",
    "#         # Save to CSV file.\n",
    "\n",
    "#         savedata = np.array(list(beats[:]), dtype=np.float)\n",
    "#         outfn = './'+fn+'_'+chname+'.csv'\n",
    "#         print('    Generating ', outfn)\n",
    "#         with open(outfn, \"wb\") as fin:\n",
    "#             np.savetxt(fin, savedata, delimiter=\",\", fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# csv_data = np.loadtxt('./mit-bih/104_V5.csv', delimiter=',')\n",
    "\n",
    "# beat_num = [0,1,2,3,4,5,6,7,8]\n",
    "\n",
    "# for beatid in beat_num:\n",
    "#     times = np.arange(187, dtype = 'float') / 187\n",
    "#     beat = csv_data[beatid][:-2]\n",
    "#     anno = csv_data[beatid][-2]\n",
    "#     plt.figure(figsize=(12,5))\n",
    "    \n",
    "#     if (anno == 1.0):\n",
    "#         plt.plot(times, beat, 'b')\n",
    "#         plt.ylabel('ann = N', size=20)\n",
    "#     elif(anno == 2.0):\n",
    "#         plt.plot(times, beat, 'r')\n",
    "#         plt.ylabel('ann = L', size=20)\n",
    "#     elif(anno == 3.0):\n",
    "#         plt.plot(times, beat, 'g')\n",
    "#         plt.ylabel('ann = R', size=20)\n",
    "#     elif(anno == 4.0):\n",
    "#         plt.plot(times, beat, 'y')\n",
    "#         plt.ylabel('ann = V', size=20)\n",
    "#     elif(anno == 5.0):\n",
    "#         plt.plot(times, beat, 'c')\n",
    "#         plt.ylabel('ann = A', size=20)\n",
    "#     elif(anno == 6.0):\n",
    "#         plt.plot(times, beat, 'm')\n",
    "#         plt.ylabel('ann = F', size=20)\n",
    "#     elif(anno == 7.0):\n",
    "#         plt.plot(times, beat, 'k')\n",
    "#         plt.ylabel('ann = f', size=20)\n",
    "#     elif(anno == 8.0):\n",
    "#         plt.plot(times, beat, 'm')\n",
    "#         plt.ylabel('ann = /', size=20)\n",
    "        \n",
    "#     plt.xlabel('Time [s]')\n",
    "#     plt.title(' | beat ' + str(beatid) + \" type \" + str(anno)+' | ')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the classifications based on the annotations.\n",
    "\n",
    "* 0.0 = undetermined\n",
    "* N = 1.0 = normal\n",
    "* L = 2.0 = LBBBB\n",
    "* R = 3.0 = RBBBB\n",
    "* V = 4.0 = Premature Ventricular contraction\n",
    "* A = 5.0 = Atrial Premature beat\n",
    "* F = 6.0 = Fusion ventricular normal beat\n",
    "* f = 7.0 = Fusion of paced and normal beat\n",
    "* / = 8.0 = paced beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.frontiersin.org/articles/10.3389/fphy.2019.00103/full\n",
    "\n",
    "https://arxiv.org/pdf/2007.02052.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# alldata = np.empty(shape=[0, 189])\n",
    "# print(alldata.shape)\n",
    "# all_csvs = glob.glob('./mit-bih/*.csv')\n",
    "# for j in all_csvs:\n",
    "#     print('Loading ', j)\n",
    "#     csvrows = np.loadtxt(j, delimiter=',')\n",
    "#     alldata = np.append(alldata, csvrows, axis=0)\n",
    "    \n",
    "# print(alldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# alldata = np.empty(shape=[0, 189])\n",
    "# print(alldata.shape)\n",
    "# all_csvs = glob.glob('./mit-bih/*.csv')\n",
    "# for j in all_csvs:\n",
    "#     print('Loading ', j)\n",
    "#     csvrows = np.loadtxt(j, delimiter=',')\n",
    "#     alldata = np.append(alldata, csvrows, axis=0)\n",
    "    \n",
    "# # create vector of random numbers, for recognizing patients.\n",
    "# # each sample should have information of the record number.\n",
    "# # add a column of the record number to identify the patient.\n",
    "\n",
    "# print(alldata.shape)\n",
    "\n",
    "# N = alldata[alldata[:,-2]==1.0]\n",
    "# L = alldata[alldata[:,-2]==2.0]\n",
    "# R = alldata[alldata[:,-2]==3.0]\n",
    "# V = alldata[alldata[:,-2]==4.0]\n",
    "# A = alldata[alldata[:,-2]==5.0]\n",
    "# F = alldata[alldata[:,-2]==6.0]\n",
    "# f = alldata[alldata[:,-2]==7.0]\n",
    "# I = alldata[alldata[:,-2]==8.0]\n",
    "\n",
    "# seed=42\n",
    "# np.random.seed(seed)\n",
    "# def downsample(arr, n, seed):\n",
    "#     downsampled = resample(arr,replace=False,n_samples=n, random_state=seed)\n",
    "#     return downsampled\n",
    "\n",
    "# def upsample(arr, n, seed):\n",
    "#     upsampled = resample(arr,replace=True,n_samples=n,random_state=seed)\n",
    "#     return upsampled\n",
    "\n",
    "# all_class = [N,L,R,V,A,F,f,I]\n",
    "# abn_class = [L,R,V,A,F,f,I]\n",
    "\n",
    "# mean_val = np.mean([len(i) for i in abn_class], dtype= int)\n",
    "# sampled_val = []\n",
    "\n",
    "# for i in all_class:\n",
    "#     if i.shape[0]> mean_val:\n",
    "#         i = downsample(i,mean_val,seed)\n",
    "#     elif i.shape[0]< mean_val:\n",
    "#         i = upsample(i, mean_val,seed)\n",
    "#     sampled_val.append(i)\n",
    "    \n",
    "# sampled_val = np.concatenate(sampled_val)\n",
    "# np.random.shuffle(sampled_val)\n",
    "# sampled_val_all = sampled_val\n",
    "\n",
    "# with open('sampled_val_all.csv', \"wb\") as fin:\n",
    "#     np.savetxt(fin, sampled_val_all, delimiter=\",\", fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  ./sampled_val_all.csv\n",
      "(41088, 189)\n",
      "(41088, 187)\n",
      "(41088,)\n",
      "(30816, 187)\n",
      "(10272, 187)\n",
      "(30816,)\n",
      "(10272,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "values = np.empty(shape=[0, 189])\n",
    "sample_val_all = glob.glob('./sampled_val_all.csv')\n",
    "\n",
    "for j in sample_val_all:\n",
    "    print('Loading ', j)\n",
    "    csvrows = np.loadtxt(j, delimiter=',')\n",
    "    values = np.append(values, csvrows, axis=0)\n",
    "    \n",
    "print(values.shape)\n",
    "    \n",
    "X = values[:,:-2]\n",
    "y = values[:,-2]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=48)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# gbc_clf = GradientBoostingClassifier(n_estimators=5)\n",
    "# gbc_clf.fit(X_train, y_train)  \n",
    "# print('Gradient Boosting Results')\n",
    "# gbc_clf.score(X_test,y_test)\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# gbc_clf = AdaBoostClassifier(n_estimators=5,random_state=48)\n",
    "# gbc_clf.fit(X_train, y_train)\n",
    "# print('Ada Boosting Results')\n",
    "# gbc_clf.score(X_test,y_test)\n",
    "\n",
    "# # using random forest classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rfc_clf = RandomForestClassifier(max_depth=1, random_state=48)\n",
    "# rfc_clf.fit(X_train, y_train)\n",
    "# rfc_clf.score(X_test, y_test)\n",
    "\n",
    "# # using naive bayes\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# NB_clf = GaussianNB()\n",
    "# NB_clf.fit(X_train, y_train)\n",
    "# NB_clf.score(X_test, y_test)\n",
    "\n",
    "# # using NN Multi Layer Perceptron classifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# NNMLP_clf = MLPClassifier(random_state=48, max_iter=50)\n",
    "# NNMLP_clf.fit(X_train, y_train)\n",
    "# NNMLP_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.svm import SVC\n",
    "# clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "# xfit = clf.fit(X_train, y_train)\n",
    "# clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# x_pca = PCA(n_components=50,random_state=42).fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tsne = TSNE(n_components=3,random_state=42,perplexity=50).fit_transform(x_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# scatter = plt.scatter(x_tsne[:,0],x_tsne[:,1], c=y_train)\n",
    "# plt.legend(*scatter.legend_elements(), title=\"Classes\",loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plt.figure(figsize=(16,16)).gca(projection='3d')\n",
    "# ax.scatter(\n",
    "#     xs=x_tsne[:,0],\n",
    "#     ys=x_tsne[:,1],\n",
    "#     zs=x_tsne[:,2],\n",
    "#     c=y_train,\n",
    "#     cmap='tab10'\n",
    "# )\n",
    "# ax.set_xlabel('pca-one')\n",
    "# ax.set_ylabel('pca-two')\n",
    "# ax.set_zlabel('pca-three')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# import umap\n",
    "\n",
    "# x_pca = PCA(n_components=2,random_state=42).fit_transform(X_train)\n",
    "# x_tsne = TSNE(n_components=2,random_state=42,perplexity=50).fit_transform(x_pca)\n",
    "# x_umap = umap.UMAP().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# scatter = plt.scatter(x_tsne[:,0],x_tsne[:,1], c=y_train)\n",
    "# plt.legend(*scatter.legend_elements(), title=\"Classes\",loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# def leave_one_patient():\n",
    "#     x = values[:,:-2]\n",
    "#     y = values[:,-2]\n",
    "#     groups = values[:,-1]\n",
    "#     lopo = LeaveOneGroupOut()\n",
    "#     lopo.get_n_splits(x,y,groups)\n",
    "#     x_train = []\n",
    "#     x_test = []\n",
    "#     y_train = []\n",
    "#     y_test = []\n",
    "#     for train_index, test_index in lopo.split(x,y,groups):\n",
    "#         x_tr, x_te = x[train_index], x[test_index]\n",
    "#         y_tr, y_te = y[train_index], y[test_index]\n",
    "#         x_train.append(x_tr)\n",
    "#         x_test.append(x_te)\n",
    "#         y_train.append(y_tr)\n",
    "#         y_test.append(y_te)\n",
    "\n",
    "#     return x_train, x_test, y_train, y_test\n",
    "\n",
    "# x_train, x_test, y_train, y_test = leave_one_patient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
